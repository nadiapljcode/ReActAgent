{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcmEaVERgviVV1fl5liBPV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadiapljcode/ReActAgent/blob/main/ReActAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###installing module - groq"
      ],
      "metadata": {
        "id": "ddbYGwM6Ks4c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Mr-eOqErut",
        "outputId": "4d926060-eb61-46e5-d9f1-d9cd8d8887cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.20.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.20.0\n"
          ]
        }
      ],
      "source": [
        "%pip install groq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###API Key"
      ],
      "metadata": {
        "id": "ITGAEmEzKzhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GROQ_API_KEY'] = \"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\""
      ],
      "metadata": {
        "id": "t1BvPcsdEwAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###First Chat Completion"
      ],
      "metadata": {
        "id": "H5tMjl8BK3No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-70b-8192\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDXzX0_jFMIW",
        "outputId": "6b3801a9-8c62-4207-c1ca-01e029d6577e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast language models have become increasingly important in natural language processing (NLP) and artificial intelligence (AI) research. Here are some reasons why:\n",
            "\n",
            "1. **Real-time Applications**: Fast language models enable real-time applications such as chatbots, virtual assistants, and language translation systems. These applications require rapid responses to provide a seamless user experience.\n",
            "2. **Efficient Processing**: Fast language models can process large volumes of text data quickly, making them ideal for applications that require rapid analysis of large datasets, such as sentiment analysis, entity extraction, and topic modeling.\n",
            "3. **Low Latency**: Fast language models reduce latency, which is critical in applications like online language translation, live subtitles, and speech-to-text systems.\n",
            "4. **Scalability**: Fast language models can handle large amounts of data and scale to meet the needs of growing datasets, making them suitable for applications like language modeling, text generation, and dialog systems.\n",
            "5. **Improved User Experience**: Fast language models can provide instant feedback, enabling users to interact more efficiently and effectively, which is particularly important in applications like language learning platforms, content generation, and text summarization.\n",
            "6. **Competitive Advantage**: Fast language models can provide a competitive advantage in industries like customer service, marketing, and advertising, where rapid response times are crucial.\n",
            "7. **Research and Development**: Fast language models accelerate research and development in NLP and AI, enabling researchers to experiment, test, and iterate more quickly.\n",
            "8. **Edge Computing**: Fast language models are essential for edge computing, where AI models are deployed on edge devices, such as smartphones, smart home devices, and autonomous vehicles, to enable real-time processing and decision-making.\n",
            "9. **Resource-Constrained Environments**: Fast language models are critical in resource-constrained environments, such as embedded systems, where computational resources are limited, and energy efficiency is essential.\n",
            "10. **Environmental Impact**: Fast language models can help reduce the environmental impact of NLP and AI by reducing energy consumption, carbon footprint, and e-waste generation associated with slower and more computationally intensive models.\n",
            "\n",
            "To achieve fast language models, researchers and developers employ various techniques, including:\n",
            "\n",
            "1. Model pruning and knowledge distillation\n",
            "2. Quantization and binary neural networks\n",
            "3. Efficient neural network architectures (e.g., Transformers, CNNs)\n",
            "4. Parallel processing and distributed computing\n",
            "5. Optimized algorithms and data structures\n",
            "6. Specialized hardware accelerators (e.g., TPUs, GPUs, FPGAs)\n",
            "\n",
            "By developing fast language models, the NLP and AI community can unlock new applications, improve user experiences, and drive innovation in various industries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Agent Code"
      ],
      "metadata": {
        "id": "IsBxn7RuK71t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "  def __init__(self, client, system):\n",
        "    self.client = client\n",
        "    self.system = system\n",
        "    self.messages = []\n",
        "    if self.system is not None:\n",
        "      self.messages.append({\"role\":\"system\", \"content\":self.system})\n",
        "\n",
        "  def __call__(self, message = \"\"):\n",
        "     if message:\n",
        "        self.messages.append({\"role\":\"user\", \"content\":message})\n",
        "     result = self.execute()\n",
        "     self.messages.append({\"role\":\"assistant\", \"content\":result})\n",
        "     return result\n",
        "\n",
        "  def execute(self):\n",
        "    completion = client.chat.completions.create(\n",
        "                  messages= self.messages,\n",
        "                  model=\"llama3-70b-8192\",\n",
        "                )\n",
        "    return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "NMkfVUlmFrxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###System Prompt\n",
        "Guides how the AI Agent should work"
      ],
      "metadata": {
        "id": "-gT3sdKsK97C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "At the end of the loop you output an Answer\n",
        "Use Thought to describe your thoughts about the question you have been asked.\n",
        "Use Action to run one of the actions available to you - then return PAUSE.\n",
        "Observation will be the result of running those actions.\n",
        "\n",
        "Your available actions are:\n",
        "\n",
        "calculate:\n",
        "e.g. calculate: 4 * 7 / 3\n",
        "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
        "\n",
        "get_planet_mass:\n",
        "e.g. get_planet_mass: Earth\n",
        "returns weight of planet in kg\n",
        "\n",
        "search_web:\n",
        "e.g. search_web: Latest AI trends\n",
        "Searches the internet and returns relevant information.\n",
        "\n",
        "Example session 1:\n",
        "Question: What is the mass of Earth times 2?\n",
        "Thought: I need to find the mass of Earth\n",
        "Action: get_planet_mass: Earth\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "Observation: 5.972e24\n",
        "\n",
        "Thought: I need to multiply this by 2\n",
        "Action: calculate: 5.972e24 * 2\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "Observation = 1,1944x10e25\n",
        "\n",
        "If you have an answer, output it as the Answer.\n",
        "Answer: The mass of the Earth times 2 is 1,1944x10e25.\n",
        "\n",
        "Example session 2:\n",
        "Question: What is the latest AI trend?\n",
        "Thought: I should search the web for AI trends.\n",
        "Action: search_web: Latest AI trends\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "Observation: AI is shifting towards multi-modal models in 2024.\n",
        "\n",
        "Answer: The latest AI trend is multi-modal models in 2024.\n",
        "Now it's your turn:\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "dAOjG_3tIbUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tools\n",
        "These tools are nothing but functions"
      ],
      "metadata": {
        "id": "SJnofDJmRbjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQkKx03-kp6_",
        "outputId": "20a48aef-9226-4d30-a7ea-6e0e0f68f8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.1.31)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32009 sha256=16897e40b06eb1c044ff6b3b8f11a107eacf91e0ee37a9e9fa53851f691b3e6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch\n",
        "import os\n",
        "\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"b77fc88580e0b26cadae31826039bac10da39bf500e36f2c1fa3c25e4e5bd263\"\n",
        "\n",
        "def search_web(query):\n",
        "    \"\"\"Searches Google using SerpAPI and returns the first result.\"\"\"\n",
        "    search = GoogleSearch({\n",
        "        \"q\": query,\n",
        "        \"api_key\": os.environ[\"SERPAPI_API_KEY\"]\n",
        "    })\n",
        "    results = search.get_dict()\n",
        "\n",
        "    if \"organic_results\" in results:\n",
        "        return results[\"organic_results\"][0][\"snippet\"]  # First search result summary\n",
        "\n",
        "    return \"No results found.\"\n",
        "\n",
        "def calculate(operation):\n",
        "  return eval(operation)\n",
        "\n",
        "def get_planet_mass(planet) -> float:\n",
        "  match planet.lower():\n",
        "    case \"earth\" :\n",
        "      return 5.972e24\n",
        "    case \"jupiter\" :\n",
        "      return 1.898e27\n",
        "    case \"mars\" :\n",
        "      return 6.39e23\n",
        "    case \"mercury\":\n",
        "      return 3.285e23\n",
        "    case \"neptune\":\n",
        "      return 1.024e26\n",
        "    case \"saturn\":\n",
        "      return 5.683e26\n",
        "    case \"uranus\":\n",
        "      return 8.681e25\n",
        "    case \"venus\":\n",
        "      return 4.867e24\n",
        "    case _:\n",
        "      return 0.0\n",
        "\n"
      ],
      "metadata": {
        "id": "HR9HRLflRhPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initializing the Agent\n",
        "Agent class has to be given two parameters: client - we have already passed, system - system_prompt"
      ],
      "metadata": {
        "id": "7px9BsTALGZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "planet_expert = Agent(client, system_prompt)"
      ],
      "metadata": {
        "id": "i8JZYC0uTDJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Start Running the Agent\n",
        "Since youre passing a message, the messsage gets appended to list of messages."
      ],
      "metadata": {
        "id": "cbGuDlGqLSke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = planet_expert(\"What is the mass of Earth times 5?\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nth4SO7YVPMZ",
        "outputId": "a71f4b8a-a9e2-43af-9a46-e7f53644e432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thought: I need to find the mass of Earth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Shows the list of all the messages in messages List"
      ],
      "metadata": {
        "id": "cPpA-06hLkri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "planet_expert.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOU-S-4TWo7x",
        "outputId": "9a64fb3c-a8bc-4f55-bcf0-c800b34c3ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': \"You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\nget_planet_mass:\\ne.g. get_planet_mass: Earth\\nreturns weight of planet in kg\\n\\nsearch_web:\\ne.g. search_web: Latest AI trends\\nSearches the internet and returns relevant information.\\n\\nExample session 1:\\nQuestion: What is the mass of Earth times 2?\\nThought: I need to find the mass of Earth\\nAction: get_planet_mass: Earth\\nPAUSE\\n\\nYou will be called again with this:\\nObservation: 5.972e24\\n\\nThought: I need to multiply this by 2\\nAction: calculate: 5.972e24 * 2\\nPAUSE\\n\\nYou will be called again with this:\\nObservation = 1,1944x10e25\\n\\nIf you have an answer, output it as the Answer.\\nAnswer: The mass of the Earth times 2 is 1,1944x10e25.\\n\\nExample session 2:\\nQuestion: What is the latest AI trend?\\nThought: I should search the web for AI trends.\\nAction: search_web: Latest AI trends\\nPAUSE\\n\\nYou will be called again with this:\\nObservation: AI is shifting towards multi-modal models in 2024.\\n\\nAnswer: The latest AI trend is multi-modal models in 2024.\\nNow it's your turn:\"},\n",
              " {'role': 'user', 'content': 'What is the mass of Earth times 5?'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Thought: I need to find the mass of Earth.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = planet_expert()\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF-7eIw0W9Qx",
        "outputId": "3683f2e9-c7ed-4b32-ab1c-04e9ebae7e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observation = get_planet_mass(\"Earth\")\n",
        "print(observation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy_EpRx7XSlY",
        "outputId": "ce5b9291-146c-4583-dc37-b07245a9cd84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.972e+24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_prompt = f\"Observation: {observation}\"\n",
        "result = planet_expert(next_prompt)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzn4pT8-7G5o",
        "outputId": "aea14669-efa5-4b56-84e4-3c311a687bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thought: I need to multiply this by 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "planet_expert.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYWoxDXe7xQZ",
        "outputId": "0bd0ceea-b7e9-4802-8285-5dffefb844a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': \"You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\nget_planet_mass:\\ne.g. get_planet_mass: Earth\\nreturns weight of planet in kg\\n\\nsearch_web:\\ne.g. search_web: Latest AI trends\\nSearches the internet and returns relevant information.\\n\\nExample session 1:\\nQuestion: What is the mass of Earth times 2?\\nThought: I need to find the mass of Earth\\nAction: get_planet_mass: Earth\\nPAUSE\\n\\nYou will be called again with this:\\nObservation: 5.972e24\\n\\nThought: I need to multiply this by 2\\nAction: calculate: 5.972e24 * 2\\nPAUSE\\n\\nYou will be called again with this:\\nObservation = 1,1944x10e25\\n\\nIf you have an answer, output it as the Answer.\\nAnswer: The mass of the Earth times 2 is 1,1944x10e25.\\n\\nExample session 2:\\nQuestion: What is the latest AI trend?\\nThought: I should search the web for AI trends.\\nAction: search_web: Latest AI trends\\nPAUSE\\n\\nYou will be called again with this:\\nObservation: AI is shifting towards multi-modal models in 2024.\\n\\nAnswer: The latest AI trend is multi-modal models in 2024.\\nNow it's your turn:\"},\n",
              " {'role': 'user', 'content': 'What is the mass of Earth times 5?'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Thought: I need to find the mass of Earth.'},\n",
              " {'role': 'assistant', 'content': ''},\n",
              " {'role': 'user', 'content': 'Observation: 5.972e+24'},\n",
              " {'role': 'assistant', 'content': 'Thought: I need to multiply this by 5'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = planet_expert()\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7K803DZ70fw",
        "outputId": "633db332-5424-478f-ff6a-516446545789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = planet_expert()\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt4mQX3477Ut",
        "outputId": "2847266c-b3ca-4cc4-aae6-1b80525c4e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observation = calculate(\"3.285e23 * 5\")\n",
        "print(observation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KD0eWyP78rG",
        "outputId": "2474dbb6-5dac-404d-bde7-88d665c3e570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6425e+24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_prompt = f\"Observation: {observation}\"\n",
        "result = planet_expert(next_prompt)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKBw8EJF8Jwc",
        "outputId": "468ce4a5-cfd7-46db-cb84-760bb613e0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: The mass of the Earth times 5 is 2.986e+25.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_prompt = f\"Observation: {observation}\"\n",
        "result = planet_expert(next_prompt)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQS1DZIh8O7Z",
        "outputId": "25efc02d-3f94-4b8c-c98c-6248563ec08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: The mass of the Earth times 5 is 2.986e+25.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "planet_expert.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncMSrzco8Rge",
        "outputId": "abe90053-c172-41ae-9dd5-5a793421f872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': \"You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\nget_planet_mass:\\ne.g. get_planet_mass: Earth\\nreturns weight of planet in kg\\n\\nsearch_web:\\ne.g. search_web: Latest AI trends\\nSearches the internet and returns relevant information.\\n\\nExample session 1:\\nQuestion: What is the mass of Earth times 2?\\nThought: I need to find the mass of Earth\\nAction: get_planet_mass: Earth\\nPAUSE\\n\\nYou will be called again with this:\\nObservation: 5.972e24\\n\\nThought: I need to multiply this by 2\\nAction: calculate: 5.972e24 * 2\\nPAUSE\\n\\nYou will be called again with this:\\nObservation = 1,1944x10e25\\n\\nIf you have an answer, output it as the Answer.\\nAnswer: The mass of the Earth times 2 is 1,1944x10e25.\\n\\nExample session 2:\\nQuestion: What is the latest AI trend?\\nThought: I should search the web for AI trends.\\nAction: search_web: Latest AI trends\\nPAUSE\\n\\nYou will be called again with this:\\nObservation: AI is shifting towards multi-modal models in 2024.\\n\\nAnswer: The latest AI trend is multi-modal models in 2024.\\nNow it's your turn:\"},\n",
              " {'role': 'user', 'content': 'What is the mass of Earth times 5?'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Thought: I need to find the mass of Earth.'},\n",
              " {'role': 'assistant', 'content': ''},\n",
              " {'role': 'user', 'content': 'Observation: 5.972e+24'},\n",
              " {'role': 'assistant', 'content': 'Thought: I need to multiply this by 5'},\n",
              " {'role': 'assistant', 'content': '.'},\n",
              " {'role': 'assistant', 'content': ''},\n",
              " {'role': 'user', 'content': 'Observation: 1.6425e+24'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Answer: The mass of the Earth times 5 is 2.986e+25.'},\n",
              " {'role': 'user', 'content': 'Observation: 1.6425e+24'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Answer: The mass of the Earth times 5 is 2.986e+25.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Run Agent in a Loop"
      ],
      "metadata": {
        "id": "7606mCCWQtUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "tool_functions = {\n",
        "    \"calculate\" : calculate,\n",
        "    \"get_planet_mass\" : get_planet_mass,\n",
        "    \"search_web\" : search_web,\n",
        "}\n",
        "\n",
        "def agent_loop(max_iterations, system, query):\n",
        "    agent = Agent(client, system_prompt)\n",
        "    tools = ['calculate', 'get_planet_mass', 'search_web']\n",
        "    next_prompt = query\n",
        "    i = 0\n",
        "    while i < max_iterations:\n",
        "        i+=1\n",
        "        result = agent(next_prompt)\n",
        "        print(result)\n",
        "        if \"PAUSE\" in result and \"Action\" in result:\n",
        "            action = re. findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
        "            chosen_tool = action[0][0]\n",
        "            arg = action[0][1]\n",
        "            if chosen_tool in tools:\n",
        "                result_tool = tool_functions[chosen_tool](arg)\n",
        "                next_prompt = f\"Observation: {result_tool}\"\n",
        "            else:\n",
        "                next_prompt = \"Observation: Tool not found\"\n",
        "            print (next_prompt)\n",
        "            continue\n",
        "        if \"Answer\" in result:\n",
        "            break"
      ],
      "metadata": {
        "id": "MFNOHv-B8VAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_loop(max_iterations = 10, system = system_prompt, query = \"what is the mass of the earth plus the mass of mercury and all of it times 5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP8vIusqTlDG",
        "outputId": "c8382725-8ba1-47bf-aa23-fe41ffacc57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thought: I need to find the mass of Earth and Mercury, then add them together and multiply by 5. \n",
            "\n",
            "Action: get_planet_mass: Earth\n",
            "PAUSE\n",
            "Observation: 5.972e+24\n",
            "Thought: I have the mass of Earth, now I need to find the mass of Mercury.\n",
            "\n",
            "Action: get_planet_mass: Mercury\n",
            "PAUSE\n",
            "Observation: 3.285e+23\n",
            "Thought: I have the masses of both Earth and Mercury, now I need to add them together.\n",
            "\n",
            "Action: calculate: 5.972e+24 + 3.285e+23\n",
            "PAUSE\n",
            "Observation: 6.300500000000001e+24\n",
            "Thought: I have the sum of the masses, now I need to multiply it by 5.\n",
            "\n",
            "Action: calculate: 6.300500000000001e+24 * 5\n",
            "PAUSE\n",
            "Observation: 3.1502500000000004e+25\n",
            "Thought: I have the final result, which is the mass of Earth plus the mass of Mercury, multiplied by 5.\n",
            "\n",
            "Answer: The mass of the Earth plus the mass of Mercury, all of it times 5, is 3.1502500000000004e+25.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_loop(max_iterations = 10, system = system_prompt, query = \"What is the capital city of India\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eKnPgpsTzsg",
        "outputId": "32705259-67f5-443e-9778-a5a2263ad739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thought: I need to find the capital city of India. \n",
            "\n",
            "Action: search_web: Capital city of India\n",
            "PAUSE\n",
            "Observation: Delhi, officially the National Capital Territory (NCT) of Delhi, is a city and a union territory of India containing New Delhi, the capital of India.\n",
            "Thought: I have found the capital city of India, which is New Delhi.\n",
            "\n",
            "Answer: The capital city of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "API_KEY = \"b77fc88580e0b26cadae31826039bac10da39bf500e36f2c1fa3c25e4e5bd263\"  # Replace with your actual API key\n",
        "queries = [\n",
        "    \"latest AI trends 2025\",\n",
        "    \"Who is the CEO of Google?\",\n",
        "    \"Python vs Java performance\",\n",
        "    \"best laptop for programming 2025\",\n",
        "    \"how does quantum computing work?\"\n",
        "]\n",
        "\n",
        "response_times = []\n",
        "accurate_results = 0\n",
        "\n",
        "for query in queries:\n",
        "    start_time = time.time()\n",
        "\n",
        "    params = {\n",
        "        \"engine\": \"google\",\n",
        "        \"q\": query,\n",
        "        \"api_key\": API_KEY\n",
        "    }\n",
        "\n",
        "    response = requests.get(\"https://serpapi.com/search\", params=params)\n",
        "    end_time = time.time()\n",
        "\n",
        "    response_time = end_time - start_time\n",
        "    response_times.append(response_time)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        first_result = data.get(\"organic_results\", [{}])[0].get(\"title\", \"\")\n",
        "\n",
        "        # Manually verify if the first result is relevant\n",
        "        print(f\"Query: {query}\")\n",
        "        print(f\"Top Result: {first_result}\\n\")\n",
        "\n",
        "        user_feedback = input(\"Is this result relevant? (yes/no): \")\n",
        "        if user_feedback.lower() == \"yes\":\n",
        "            accurate_results += 1\n",
        "\n",
        "# Calculate average response time and accuracy\n",
        "avg_response_time = sum(response_times) / len(response_times)\n",
        "accuracy = (accurate_results / len(queries)) * 100\n",
        "\n",
        "print(f\"Average Response Time: {avg_response_time:.2f} seconds\")\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "xjRVmO82jFFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4749f0d-7d31-4ab7-8b0f-d2a03335bf27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: latest AI trends 2025\n",
            "Top Result: 5 AI Trends Shaping Innovation and ROI in 2025\n",
            "\n",
            "Is this result relevant? (yes/no): yes\n",
            "Query: Who is the CEO of Google?\n",
            "Top Result: Sundar Pichai\n",
            "\n",
            "Is this result relevant? (yes/no): yes\n",
            "Query: Python vs Java performance\n",
            "Top Result: Is java faster than python? : r/AskProgramming\n",
            "\n",
            "Is this result relevant? (yes/no): no\n",
            "Query: best laptop for programming 2025\n",
            "Top Result: Best laptop for programming of 2025: top picks tested for ...\n",
            "\n",
            "Is this result relevant? (yes/no): yes\n",
            "Query: how does quantum computing work?\n",
            "Top Result: What Is Quantum Computing?\n",
            "\n",
            "Is this result relevant? (yes/no): yes\n",
            "Average Response Time: 1.44 seconds\n",
            "Accuracy: 80.00%\n"
          ]
        }
      ]
    }
  ]
}